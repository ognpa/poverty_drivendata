{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline implementation\n",
    "\n",
    "In this notebook, I will try to explore sklearn's `Pipeline` to implement the entire workflow of this project. This will enable me to easily crossvalidate and check results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing and feature selection\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metafeatures(df):\n",
    "    \"\"\"\n",
    "    Get metadata of the columns in the training set.\n",
    "    \n",
    "    Returns a metadata DataFrame.\n",
    "    \"\"\"\n",
    "    logging.info('Creating metafeatures dataframe.')\n",
    "    metafeatures = []\n",
    "    rows = df.shape[0]\n",
    "    for col in df.columns:\n",
    "        d = {'column': col,\n",
    "             'n_unique': df[col].nunique(),\n",
    "             'missing': df[col].isnull().sum()*1.0/rows,\n",
    "             'type': df[col].dtype}\n",
    "        metafeatures.append(d)\n",
    "    return pd.DataFrame(metafeatures)\n",
    "\n",
    "def le_columns(df, columns):\n",
    "    \"\"\"Feature engineering and cleaning, prepare for training.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    df: dataframe\n",
    "    columns: list of categorical columns\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Transformed dataframe\n",
    "    \"\"\"\n",
    "    logging.info('LabelEncoder for %s columns', len(columns))\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:\n",
    "        df.loc[:, col] = le.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "def get_cols(df):\n",
    "    \"\"\"Returns list of categorical columns and columns to drop.\"\"\"\n",
    "    meta = get_metafeatures(df)\n",
    "    categorical_columns = meta.loc[meta['type'] == 'object', 'column'].tolist()\n",
    "    cols_to_drop = meta.loc[meta['missing'] > 0.5, 'column'].tolist()\n",
    "    return categorical_columns, cols_to_drop\n",
    "\n",
    "def get_X_y(df):\n",
    "    \"\"\"Drop columns, build features, impute missing values and return X and y,\n",
    "    for training.\"\"\"\n",
    "    cat_cols, cols_to_drop = get_cols(df)\n",
    "    df = df.pipe(le_columns, cat_cols)\n",
    "    feature_columns = set(df.columns) - set(['id', 'country', 'poor']) - set(cols_to_drop)\n",
    "    X = df.loc[:, feature_columns].as_matrix()\n",
    "    try:\n",
    "        y = df.loc[:, 'poor'].as_matrix()\n",
    "    except:\n",
    "        y = None\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('feature_selection', SelectFromModel(LogisticRegression(penalty=\"l1\"))),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "rf_param_grid = [\n",
    "    {\n",
    "        'imputer__strategy': ['mean', 'median'],\n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__class_weight': ['balanced_subsample', 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "rf_grid = GridSearchCV(rf_pipe, cv=10, n_jobs=-1, param_grid=rf_param_grid, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "lr_param_grid = [\n",
    "    {\n",
    "        'imputer__strategy': ['mean', 'median'],\n",
    "        'clf__penalty': ['l1'],\n",
    "        'clf__C': [0.01, 0.1, 1, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "lr_grid = GridSearchCV(lr_pipe, cv=10, n_jobs=-1, param_grid=lr_param_grid, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_pipe = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('clf', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "etc_param_grid = [\n",
    "    {\n",
    "        'imputer__strategy': ['mean', 'median'],\n",
    "        'clf__criterion': ['entropy', 'gini'],\n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__class_weight': ['balanced_subsample', 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "etc_grid = GridSearchCV(etc_pipe, cv=10, n_jobs=-1, param_grid=etc_param_grid, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('clf', XGBClassifier())\n",
    "])\n",
    "\n",
    "xgb_param_grid = [\n",
    "    {\n",
    "        'imputer__strategy': ['mean', 'median'],\n",
    "        'clf__objective': ['binary:logistic']\n",
    "    }\n",
    "]\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_pipe, cv=10, n_jobs=-1, param_grid=xgb_param_grid, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tests - train classifier and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cv_score(country, grid):\n",
    "    \"\"\"Check local cv scores using a train-test split of 80-20.\"\"\"\n",
    "    df = pd.read_csv('../data/raw/{}_hhold_train.csv'.format(country))\n",
    "    X, y = get_X_y(df)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    preds = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "    return log_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(country, grid):\n",
    "    \"\"\"Replacement for main function\"\"\"\n",
    "    df = pd.read_csv('../data/raw/{}_hhold_train.csv'.format(country))\n",
    "    X, y = get_X_y(df)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    test = pd.read_csv('../data/raw/{}_hhold_test.csv'.format(country))\n",
    "    X_test, _ = get_X_y(test)\n",
    "    preds = grid.best_estimator_.predict_proba(X_test)\n",
    "    return preds, test\n",
    "\n",
    "def make_subs(preds, test_feat, country):\n",
    "    \"\"\"Make submission.\"\"\"\n",
    "    country_sub = pd.DataFrame(data=preds[:, 1],\n",
    "                               columns=['poor'],\n",
    "                               index=test_feat['id'])\n",
    "    # add country code for joining later\n",
    "    country_sub['country'] = country\n",
    "    # write submission\n",
    "    return country_sub[['country', 'poor']].reset_index()\n",
    "\n",
    "def main(country, grid):\n",
    "    \"\"\"Everything packaged here.\"\"\"\n",
    "    preds, test = get_predictions(country, grid)\n",
    "    return make_subs(preds, test, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_a = main('A', xgb_grid)\n",
    "sub_b = main('B', xgb_grid)\n",
    "sub_c = main('C', xgb_grid)\n",
    "submissions = pd.concat([sub_a, sub_b, sub_c])\n",
    "submissions.to_csv('../data/processed/xgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
